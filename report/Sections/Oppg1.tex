\section{Task 1}

We consider reaction-diffusion equations, which have the form
\begin{equation}
    \label{eq:original_eq}
     u_t = \mu u_{xx} + f(u)
\end{equation}
where $\mu$ is a positive constant.
We also assume that the reaction term,
$f(u)$, is a linear function in \( u \).
That is, it can be written as \( f(u) = au \)
for some constant \( a \in \mathbb{R}, a \neq 0 \).
Furthermore, we solve the equation on
the grid \( (x, t) \in [0, 1] \times [0, T] \)
with boundary conditions given by functions
\( f, g_1 \) and \( g_2 \):
\begin{align*}
  u(0, x) &= f(x) \\
  u(t, 0) &= g_1(t) \\
  u(t, 1) &= g_2(t)
\end{align*}

\subsection{Discretization}

We discretize the domain in both space and time,
such that $x_m = mh$ and $t_n = nk$,
where \( m = 0, 1, \dots, M + 1\) and \( n = 0, 1, \dots, N \)
for some positive integers \( M, N \).
We denote by \( U_m^n = U(t_n, x_m) \) the approximation
of the exact solution \( u_m^n = u(t_n, x_m) \).

\begin{figure}[!h]
  \centering
  \label{fig:disc}
  \resizebox{0.45\columnwidth}{!}{%
  \begin{tikzpicture}
    %grid
    \draw[help lines, step=0.5] (0,0) grid (4, 4);

    % axes
    \draw[thick,->] (0,0) -- (4.5,0) node[anchor=north west] {\( x \)};
    \draw[thick,->] (0,0) -- (0,4.5) node[anchor=south east] {\( t \)};

    % lines at y=1 and x=1
    \draw[thick] (-2pt,4) node[anchor=east] {\( T \)} -- (4,4) ; 
    \draw[thick] (4,-2pt) node[anchor=north] {\( 1 \)} -- (4,4) ; 
    \draw[thick] (-2pt,0) node[anchor=east] {\( 0 \)} -- (4,0) ; 
    \draw[thick] (0,-2pt) node[anchor=north] {\( 0 \)} -- (0,4) ; 

    % initial condition
    \draw[blue, thick] (0,0) -- node[below] {\( f(x) \)} (4,0); 

    % boundary conditions
    \draw[red, thick] (0,0) -- node[left] {\( g_1(t) \)} (0,4); 
    \draw[red, thick] (4,0)  -- node[right] {\( g_2(t) \)} (4,4); 

    % point in grid
    \fill (1.5, 1) circle (2pt) node[above right] {\( (x_m, t_n) \)};
  \end{tikzpicture}
}
  \caption{The domain \( [0, 1] \times [0, T] \),
    with boundary and initial conditions
    given by functions \( f, g_1 \) and \( g_2 \).
  }
\end{figure}

A scheme based on forward and backward Euler,
together with a central difference in space, could be
$$
  \frac{1}{k}\nabla_tU_{m}^{n+1}=\frac{\mu}{h^2}\delta_x^2U_{m}^{n+1}+f(U_{m}^{n} ),
$$
which can be rewritten to 
\begin{equation}
  \label{eq:scheme}
  U_{m}^{n+1} = U_{m}^{n} + r (U_{m+1}^{n+1}-2U_{m}^{n+1}+U_{m-1}^{n+1}) + kf(U_{m}^{n}), \quad r = \mu\frac{k}{h^2}.
\end{equation}
Time dependent PDEs with diffusion terms should be solved using implicit methods.
This requires solving a nonlinear system for each step.
The following scheme is based on an implicit method
for the diffusion term and an explicit method for the reaction term.
\begin{align}
  \label{eq:scheme_implicit_eq}
  U_{m}^{*} &= U_{m}^{n} +\frac{r}{2}(\delta_x^2 U_{m}^{*} + \delta_x^2 U_{m}^{n} ) + kf(U_{m}^{n}) \\
  \label{eq:scheme_explicit_eq}
    U_{m}^{n+1} &= U_{m}^{*} + \frac{k}{2}(f(U_{m}^{*}) - f(U_{m}^{n})) \\
  \label{eq:scheme_boundary}
    U_0^n &= g_1(t_n), \quad U_{M+1}^n = g_2(t_n)
\end{align}

\subsection{Stability analysis}

Define the matrix \( S = \text{tridiag}(1, -2, 1) \in \text{Mat}_{M,M}(\mathbb{R}) \).
That is,
\begin{equation}
  \label{eq:Smatrix}
  S = 
  \begin{bmatrix}
    -2 & 1 &  &  & \\
    1& -2 & 1 &  & \\
     & \ddots & \ddots & \ddots & \\
     &  & 1 & -2 & 1\\
     &  &  & 1 & -2\\
  \end{bmatrix}.
\end{equation}
Let \( U^n = [U_1^n, U_2^n, \dots, U_M^n]^T \).
Furthermore, let \( I \) be the \( M \times M \) identity matrix and
let \( \rho(C) \) denote the spectral radius of the matrix \( C \).
The scaled \( 2 \)-norm will come in handy.
It is defined as follows:
\[
  \lVert v \rVert_{2,h} = \sqrt{h}\lVert v \rVert_2
\]

Before we go on with the stability analysis we need some results
concerning the matrix \( S \).

\begin{lemma}
  \label{lemma:S_diagonalizable}
  Let \( S \in \text{Mat}_{M,M}(\mathbb{R}) \) be defined as in \eqref{eq:Smatrix}.
  Then \( S \) is diagonalizable by an orthogonal matrix \( P \).
  That is, \( S = P \Lambda P^T \), for some diagonal matrix \( \Lambda \).
  The eigenvalues of \( S \) are found on the diagonal of \( \Lambda \):
  \[
    \lambda_m = - 4 \sin^2 \phi_m,
  \]
  where \( \phi_m = \frac{m \pi}{2(M+1)} \) for \(m = 1, \dots, M. \)
\end{lemma}
\begin{proof}
    Problem \( 1 \) of exercise set \( 1 \).
\end{proof}

\begin{lemma}
  \label{lemma:existance_of_inverse}
Let \( S \in \text{Mat}_{M,M}(\mathbb{R}) \) be defined as in \eqref{eq:Smatrix},
and let \( r \) be defined as in \eqref{eq:scheme}.
  Then \( I - \frac{r}{2} S\) is invertible.
\end{lemma}
\begin{proof}
  \( I - \frac{r}{2} S \) is invertible iff all the eigenvalues are nonzero.
  From lemma \ref{lemma:S_diagonalizable} we we have a diagonalization of \( S \). Thus
  \begin{equation*}
      I - \frac{r}{2} S
      = PP^T - \frac{r}{2} P\Lambda P^T
      = P \left(I - \frac{r}{2} \Lambda \right) P^T
  \end{equation*}
  The eigenvalues of \( I - \frac{r}{2}S \) are
  \( 1 - \frac{r}{2} \lambda_m\),
  where the set \( \{\lambda_m\}_{m=1,\dots,M} \) are the eigenvalues of \( S \).
  Observe that \( r > 0 \) and \( \lambda_m < 0 \) for all \( m = 1, \dots, M \).
  Hence
  \[
    1 - \frac{r}{2} \lambda_m > 1 \neq 0
  \]
  for all \( m = 1, \dots, M \), so the matrix is invertible.
\end{proof}

Rewrite \eqref{eq:scheme_implicit_eq} as a matrix-vector equation
and collect \( U^* \) on the left hand side.
\begin{equation}
  \left(I - \frac{r}{2}S\right)U^* = \left(I + kaI + \frac{r}{2}S\right) U^n
\end{equation}

\( I - \frac{r}{2}S \) is invertible
by lemma \ref{lemma:existance_of_inverse}.
We substitute for \( U^* \)
in \eqref{eq:scheme_explicit_eq}
and arrive at an expression for the matrix \( C \)
satisfying \( U^{n+1} = C U^n \).
\begin{align*}
  U^{n+1} &= U^* + \frac{ka}{2}\left(U^*  - U^n\right) \\
          &= \left(1 + \frac{ka}{2}\right) {\left[I - \frac{r}{2}S\right]}^{-1} \left(I + kaI + \frac{r}{2}S\right) U^n - \frac{ka}{2}U^n \\
          &= {\left[I - \frac{r}{2}S\right]}^{-1} \left( \left(1+ka+\frac{1}{2}(ka)^2\right)I + \frac{1}{2}\left(1+ka\right)rS\right) U^n
\end{align*}

So
\begin{equation}
    C = {\left[I - \frac{r}{2}S\right]}^{-1} \left( \left(1+ka+\frac{1}{2}(ka)^2\right)I + \frac{1}{2}\left(1+ka\right)rS\right).
  \end{equation}

By exploiting lemma \ref{lemma:S_diagonalizable} once more
we arrive at a diagonalization for \( C \).
\begin{align*}
  C &= {\left[PP^T - \frac{r}{2}P\Lambda P^T\right]}^{-1} \left( \left(1+ka+\frac{1}{2}(ka)^2\right)PP^T + \frac{1}{2}\left(1+ka\right)r P\Lambda P^T\right) \\
    &= P{\left[I - \frac{r}{2}\Lambda \right]}^{-1} \left( \left(1+ka+\frac{1}{2}(ka)^2\right)I + \frac{1}{2}\left(1+ka\right)r \Lambda \right) P^T \\
    &= P \Delta P^T
\end{align*}
where
\begin{equation}
    \Delta = {\left[I - \frac{r}{2}\Lambda \right]}^{-1} \left( \left(1+ka+\frac{1}{2}(ka)^2\right)I + \frac{1}{2}\left(1+ka\right)r \Lambda \right)
\end{equation}

We observe that \( C \) is symmetric
since \( C = P \Delta P^T = P \Delta^T P^T = \left(P \Delta P^T\right)^T = C^T \).
This is nice since now the condition
\( \rho(C) \le 1 + \nu k \) is
both necessary \textit{and} \textit{sufficient} for stability
when we use \( ||\cdot||_{2,h} \).
In particular we have that \( ||C||_{2,h} = \rho(C) \)
for a symmetric matrix \( C \).

The eigenvalues for \( C \) are found on the diagonal of \( \Delta \).
\begin{equation}
  \Delta_m =
      \frac{1+ka+\frac{1}{2}(ka)^2 + \frac{1}{2}\left(1+ka\right)r \lambda_m}
      {1 - \frac{r}{2} \lambda_m}
\end{equation}

Bounding \( \rho(C) = \max_{m} \lvert \Delta_m \rvert \).
\begin{align*}
  \left\lvert \Delta_m \right\rvert &= 
\left\lvert \frac{1+ka+\frac{1}{2}(ka)^2 + \frac{1}{2}\left(1+ka\right)r \lambda_m}
{1 - \frac{r}{2} \lambda_m} \right\rvert \\
 &= 
 \left\lvert \left(1+ka\right)\frac{1+\frac{1}{2}r \lambda_m}{1 - \frac{1}{2}r \lambda_m} + \frac{1}{2}(ka)^2 \frac{1}{1 - \frac{1}{2}r \lambda_m} \right\rvert \\
 &\le \left\lvert 1+ka \right\rvert \left\lvert \frac{1+\frac{1}{2}r \lambda_m}{1 - \frac{1}{2}r \lambda_m} \right\rvert + \frac{1}{2}(ka)^2 \left\lvert\frac{1}{1 - \frac{1}{2}r \lambda_m} \right\rvert
\end{align*}
   Note that \( -1 < \lambda_m < 0  \) for all \( m = 1, \dots, M \).
   In addition, the step size \( k \) is bounded by the length of
   the time domain, \( T \).
  We simplify further.
\begin{align*}
 \left\lvert \Delta_m \right\rvert
 &\le \left\lvert 1 + ka \right\rvert + \frac{1}{2} (ka)^2
 = 1 + (\lvert a \rvert + \frac{1}{2}k a^2 )k
 \le 1 + (\lvert a \rvert + \frac{1}{2}T a^2)k
  = 1 + \nu k
\end{align*}

Finally, we have arrived at the expression needed for stability
without imposing any conditions on the scheme.
We summarize our discussion in a theorem.

\begin{theorem}
    \label{stability}
  The scheme given in equations \eqref{eq:scheme_implicit_eq}
  and \eqref{eq:scheme_explicit_eq} is unconditionally stable
  with respect to \( \lVert \cdot \rVert_{2,h} \).
\end{theorem}

\subsection{Consistency}

\iffalse
\begin{lemma}
    \label{central_difference}
    $$\delta_x^2u_{m}^{n} = h^2\partial_x^2 u_{m}^{n} + \mathcal{O}(h^4)$$
\end{lemma}
\begin{proof}
    $$\delta_x^2u_{m}^{n} = u_{m+1}^{n} - 2 u_{m}^{n} + u_{m-1}^{n}$$
    Then Taylor expand around $u_{m}^{n}$.
    \begin{align*}
        \delta_x^2u_{m}^{n} =& u_{m}^{n}  + h\partial_xu_{m}^{n} + \frac{h^2}{2}\partial_x^2 + \frac{h^3}{3!}\partial_x^3 u_{m}^{n} + \frac{h^4}{4!}\partial_x^4 u_{m}^{n} + \mathcal{O}(h^5) \\
        -&2u_{m}^{n} \\
        +& u_{m}^{n} - h\partial_xu_{m}^{n} + \frac{h^2}{2}\partial_x^2 u_{m}^{n} - \frac{h^3}{3!}\partial_x^3u_{m}^{n} + \frac{h^4}{4!}\partial_x^4 u_{m}^{n} + \mathcal{O}(h^5) \\
        =& h^2\partial_x^2 u_{m}^{n} + \frac{h^4}{12}\partial_x^4 u_{m}^{n} + \mathcal{O}(h^5) \\
        =&  h^2\partial_x^2 u_{m}^{n} + \mathcal{O}(h^4)
    \end{align*}
\end{proof}
\fi

\begin{theorem}
    \label{consistent}
  Given that $u$ is sufficiently smooth and $k \neq \frac{-2}{a}$, the local truncation error of the method is of order $\mathcal{O}(k^2 + h^2)$.
\end{theorem}

\begin{proof}
  For the boundaries we get $\tau_0=\tau_{M+1}= 0$ since we have Dirichlet boundary conditions and the approximations are exact.
  For the inner points we rewrite (\ref{eq:scheme_explicit_eq}) to an explicit equation for $U_m^*$,
  $$
    U_{m}^{*}= \frac{U_{m}^{n+1}+\frac{ka}{2}U_{m}^{n}}{1+\frac{ka}{2}}.$$
    This is then substituted into (\ref{eq:scheme_implicit_eq}) to remove $U_{m}^{*}$ from the equation. 
    Multiply by $(1+\frac{ka}{2})$ and rearrange the terms.
    $$
    U_{m}^{n+1}=\left(1+ ka + \frac{1}{2}(ka)^2\right)U_{m}^{n} + \frac{r}{2}\left((1+ka)\delta_x^2U_{m}^{n} +\delta_x^2U_{m}^{n+1}\right)
    $$
    \iffalse
    $$\frac{U_{m}^{n+1}+\frac{ka}{2}U_{m}^{n}}{1+\frac{ka}{2}} = (1+ka)U_{m}^{n}+\frac{r}{2}\left( \frac{\delta_x^2(U_{m}^{n+1}+\frac{ka}{2}U_{m}^{n})}{1+\frac{ka}{2}}  + \delta_x^2 U_{m}^{n}\right).$$
  \fi
    Then the approximations are replaced by $u$ and the local truncation error is therefore introduced.
    $$
    k\tau_m^n + u_{m}^{n+1} = \left(1+ ka + \frac{1}{2}(ka)^2\right)u_{m}^{n} + \frac{r}{2}\left((1+ka)\delta_x^2u_{m}^{n} +\delta_x^2u_{m}^{n+1}\right)
    $$
    Taylor expand around \( u_m^n \) and substitute
    \( \partial_x^2 \) for \( \delta_x^2 \),
    picking up some more error terms.
    \begin{align*}
      k \tau_m^n &= \left( 1 + ka + \frac{1}{2}(ka)^2\right)u_{m}^{n} - u_{m}^{n+1}+\frac{\mu k}{2h^2} \left(h^2\partial_x^2 u_{m}^{n+1} + \left( 1+ka \right) h^2 \partial_x^2u_{m}^{n} + \mathcal{O}(h^4)\right) \\
      &= \left( 1 + ka + \frac{1}{2}(ka)^2\right)u_{m}^{n} - u_{m}^{n} - k \partial_tu_{m}^{n} - \frac{k^2}{2} \partial_t^2 u_{m}^{n} + \mathcal{O}(k^3)  \\
      &\qquad+ \frac{\mu k}{2} \biggl( \partial_x^2 \left( u_{m}^{n} + k \partial_t u_{m}^{n} + \mathcal{O}(k^2)\right) + \left( 1 + ka\right) \partial_x^2  u_{m}^{n} \biggr) + \mathcal{O}(kh^2)
    \end{align*}
    This expression is then divided by $k$ and rearranged to 
    $$\tau_m^n = a u_{m}^{n} - \partial_tu_{m}^{n} + 2 \frac{\mu}{2}\left( \partial_x^2 u_{m}^{n}\right) +  \frac{ka^2}{2}u_{m}^{n}  - \frac{k}{2} \partial_t^2 u_{m}^{n} + \frac{\mu }{2}\left( k \partial_x^2 \partial_t u_{m}^{n}  + ka \partial_x^2  u_{m}^{n} \right) + \mathcal{O}(k^2 + h^2).$$
    The first three terms are simply (\ref{eq:original_eq}) with all terms moved to the right hand side. Some terms can also be rewritten using (\ref{eq:original_eq}), $\mu \partial_x^2u_{m}^{n} = \partial_t u_{m}^{n} - au_{m}^{n}$.
    \begin{align*}
      \tau_m^n &= \frac{ka^2}{2}u_{m}^{n}  - \frac{k}{2} \partial_t^2 u_{m}^{n} + \frac{k}{2} \partial_t \left(\partial_t u_{m}^{n}   - au_{m}^{n} \right) + \frac{ka}{2} \left( \partial_t  u_{m}^{n} - a u_{m}^{n}\right)+ \mathcal{O}(k^2 + h^2) \\
                                                                                  &= \frac{ka^2}{2}u_{m}^{n} - \frac{ka^2}{2}u_{m}^{n}  - \frac{k}{2} \partial_t^2 u_{m}^{n} + \frac{k}{2} \partial_t^2 u_{m}^{n} - \frac{ka}{2} \partial_t u_{m}^{n} + \frac{ka}{2} \partial_t  u_{m}^{n}+ \mathcal{O}(k^2 + h^2)
    \end{align*}
    Many terms cancel and we are left with \( \tau_m^n = \mathcal{O}(k^2 + h^2) \).
\end{proof}

\begin{corollary}
    \label{corollary:norm_tau}
    $\lVert\tau^s \rVert_{2, h} =\mathcal{O}(k^2 + h^2)$ for all \( s = 0, \dots, N \).
\end{corollary}

\begin{proof}
We use theorem \ref{consistent} for an upper bound of $\lvert \tau_m^n\lvert$.
    $$
    \lVert\tau^s \lVert_{2, h} = \sqrt{h}\left( \sum_{i=0}^{M+1} \lvert\tau^s_i \lvert^2 \right)^\frac{1}{2} \leq \sqrt{h}\left( \sum_{i=0}^{M+1} R(k^2 + h^2) \right)^\frac{1}{2} = \sqrt{h}\left[ (M+2) R^2(k^2+h^2)^2 \right]^\frac{1}{2}.
    $$
    Furthermore, $h = \frac{1}{M+1}$, so
    $$\lVert\tau^s \lVert_{2, h}
      \le \frac{\sqrt{M+2}}{\sqrt{M+1}}R(k^2+h^2)
      \le \sqrt{ \frac{3}{2}} R(k^2+h^2) 
    $$
\end{proof}

\begin{theorem}
  \label{thm:conv_order}
    Given that $u$ is sufficiently smooth and $k \neq \frac{-2}{a}$, the scheme is convergent of order $ \mathcal{O}(k^2+h^2)$ with respect to $\lVert\cdot \lVert_{2, h}$.
\end{theorem}

\begin{proof}
    The method is stable, theorem \ref{stability}, and consistent, theorem \ref{consistent}, and therefore convergent by Lax' equivalence theorem. We also need to prove the order of convergence.
    The scheme can be written in the form
    $$\left(I - \frac{r}{2}S \right)U_{m}^{n+1} = \left( \left(1+ka+\frac{1}{2}(ka)^2\right)I + \frac{1}{2}\left(1+ka\right)rS\right)U_{m}^n$$
    or using $A = \left(I - \frac{r}{2}S \right)$ and $B = \left( \left(1+ka+\frac{1}{2}(ka)^2\right)I + \frac{1}{2}\left(1+ka\right)rS\right)$ as
    $$AU_{m}^{n+1} = BU_{m}^{n}.$$
    If we place $U_m^n - u_m^n$ into the equation instead, we get
    $$
    AE^{n+1} = BE^n - k\tau^n.
    $$
    Exchanging $n+1$ with $n$, multiplying by $A^{-1}$,
    which exists by lemma \ref{lemma:existance_of_inverse}
    $$E^{n+1} = A^{-1}BE^{n} -kA^{-1}\tau^n$$
    we set $q^{n}= -kA^{-1}\tau^n$ and $C=A^{-1}B$.
    $$E^{n+1} = CE^{n}+q^{n}$$
    Using the term recursively, we get
    $$
    E^{n+1} = C^{n+1}E^{0}+C^{n}q^0 + C^{n-1}q^1 + \dots + C q^{n-1} + q^{n}.
    $$
    Taking the norm on both sides and using stability from theorem \ref{stability} to give a bound $L$ for $\lVert C^{n+1} \lVert$.
    $$\lVert E^{n+1}\rVert_{2,h}  \leq L\sum_{s=0}^{n}\lVert q^s \rVert_{2,h}$$
    We the use that 
    $$\lVert q^s \rVert_{2,h} \leq k \lVert A^{-1} \rVert_{2,h} \lVert\tau^s \rVert_{2,h} \leq k \tilde{K} \lVert\tau^s \rVert_{2,h}$$
    and, using $(n+1)k\leq (N+1)k=T+k\le 2T = \tilde{T}$, obtain
    $$
    \lVert E^{n+1} \rVert_{2,h}
    \leq L \tilde{K}(n+1)k \max_{0\leq s \leq n} \lVert \tau^s\rVert_{2,h}
    \leq L \tilde{K}\tilde{T}\max_{0\leq s \leq n} \lVert \tau^s\rVert_{2,h}.
    $$
    By corollary \ref{corollary:norm_tau}
    $$
    \lVert E^{n+1} \rVert_{2, h} \leq L \tilde{K}\tilde{T}\tilde{R}(k^2+h^2).
    $$
  Hence, \( \lVert E^{n+1} \rVert_{2, h} = \mathcal{O}(k^2 + h^2)\).
\end{proof}

\subsection{Numerical experiments}
We use the following solution to construct a test equation:
\begin{equation}
  \tilde{u}(t, x) = \text{e}^{-(\mu b + a)t} \sin (bx + \varphi)
\end{equation}
\( \mu  \) and \( a \) are the constants from the original problem.
Then we set \( \mu = 1/5, b = 3\pi/2, a = 1 \) and \( \varphi = \pi/4 \),
and solve it on the domain \( [0,1] \times [0,1] \).
The convergence plots in figure \ref{fig:conv_plot}
show that the order of convergence is quadratic both in
time and space.
This aligns with theorem \ref{thm:conv_order}.
\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Images/plots/task1_error.pdf}
    \caption{ The global error decreases quadratically
      with the step sizes \( k \) and \( h \).
      When both \( k \) and \( h \) tends to zero
      simultaneously, the global error also
      decreases quadratically.
    }
    \label{fig:conv_plot}
\end{figure}
